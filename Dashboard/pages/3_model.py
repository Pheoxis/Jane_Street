
import streamlit as st 
from streamlit_extras.switch_page_button import switch_page
from PIL import Image
from pathlib import Path

st.set_page_config(
    page_title="Modelowanie",
    page_icon="ğŸ“Š",
    layout="wide",
)

BASE_DIR = Path(__file__).resolve().parent
DASHBOARD_DIR = BASE_DIR.parent

st.markdown("""
    <style>
        /* General settings */
        body {
            background-color: #F5F5F5;
            color: #333333;
            font-family: 'sans serif';
        }
        /* Dataframe styling */
        .dataframe {
            background-color: #FFFFFF;
            border-radius: 10px;
            padding: 10px;
            margin-bottom: 20px;
        }
        
        /* Button styling */
        div.stButton > button {
            background-color: #4CAF50;
            color: white;
            border: none;
            padding: 10px 20px;
            text-align: center;
            text-decoration: none;
            display: inline-block;
            font-size: 16px;
            margin: 4px 2px;
            cursor: pointer;
            border-radius: 12px;
        }
        div.stButton > button:hover {
            background-color: #45a049;
        }

        /* Center image styling */
        .centered-image {
            display: flex;
            justify-content: center;
            align-items: center;
            margin-top: 20px;
            margin-bottom: 20px;
        }
    </style>
""", unsafe_allow_html=True)

st.title("ğŸ“Š Modelowanie")
st.markdown("---")

st.subheader("Analiza modelu")

image = Image.open(DASHBOARD_DIR/'imiges/cechySHAP.png')
st.image(image, width=500, use_container_width=False)

st.markdown('''
            Wykres przedstawia 20 najwaÅ¼niejszych cech modelu wedÅ‚ug wartoÅ›ci SHAP, co oznacza ich wpÅ‚yw na przewidywanie 'responder_6'. 

OÅ› Y â€“ zawiera nazwy cech, w tym 79 standardowych funkcji (feature_00 do feature_78) oraz 9 historycznych (responder_0_lag_1 do responder_8_lag_1).
OÅ› X â€“ reprezentuje wartoÅ›ci SHAP, ktÃ³re wskazujÄ…, jak mocno dana cecha wpÅ‚ywa na predykcjÄ™ modelu. Im wyÅ¼sza wartoÅ›Ä‡, tym wiÄ™kszy wpÅ‚yw cechy na wynik.
            ''')

st.markdown("---")
image = Image.open(DASHBOARD_DIR/'imiges/RozkÅ‚ad.png')
st.image(image, width=500, use_container_width=False)

st.markdown('''
            Wykres przedstawia rozkÅ‚ad wag w modelu zespoÅ‚owym, skÅ‚adajÄ…cym siÄ™ z trzech modeli LightGBM (LGB) i dwÃ³ch modeli XGBoost (XGB). OÅ› pionowa pokazuje nazwy uÅ¼ytych modeli, a oÅ› pozioma reprezentuje ich znormalizowany wkÅ‚ad wagowy w koÅ„cowÄ… predykcjÄ™.

Wagi te odzwierciedlajÄ… znaczenie poszczegÃ³lnych modeli w ostatecznym wyniku ensemble â€“ im wyÅ¼sza wartoÅ›Ä‡, tym wiÄ™kszy wpÅ‚yw danego modelu na wynik. Wszystkie wartoÅ›ci zostaÅ‚y znormalizowane tak, aby ich suma wynosiÅ‚a 1, co pozwala lepiej porÃ³wnaÄ‡ ich wzglÄ™dne znaczenie.

MoÅ¼na zauwaÅ¼yÄ‡, Å¼e niektÃ³re modele majÄ… wiÄ™kszy udziaÅ‚ niÅ¼ inne, co oznacza, Å¼e ich predykcje sÄ… bardziej istotne dla koÅ„cowego wyniku. JeÅ›li ktÃ³ryÅ› z modeli miaÅ‚by bardzo niskÄ… wagÄ™, oznaczaÅ‚oby to, Å¼e jego wpÅ‚yw na finalnÄ… decyzjÄ™ jest marginalny.
            ''')
st.markdown("---")

st.subheader('''
             Weighted Ensemble â€“ Podsumowanie:

RÂ² = 0.264 â€“ najlepszy wynik.  
Bayesowska optymalizacja (Optuna):  
Indywidualne hiperparametry dla kaÅ¼dego modelu (LightGBM & XGBoost).  
Dynamiczny dobÃ³r wag:  
Modele lepiej dopasowane otrzymujÄ… wyÅ¼sze wagi.  
Imputacja:  
Strategia "constant" z wartoÅ›ciÄ… 9999.  
Ray Tune:  
Wybrany ze wzglÄ™du na ograniczenia AutoGluon i PyCaret przy obsÅ‚udze Dask DataFrame.
             ''')

st.markdown("---")

st.markdown('''
    **Modele LightGBM**:
W trenowanych trzech modelach LightGBM dobrano miÄ™dzy innymi nastÄ™pujÄ…ce hiperparametry:

Learning rate: WartoÅ›ci oscylowaÅ‚y wokÃ³Å‚ 0.012â€“0.059, co wpÅ‚ywa na tempo uczenia siÄ™ modelu.
Liczba liÅ›ci (num_leaves): Ustalono wartoÅ›ci od 36 do 90, co okreÅ›la zÅ‚oÅ¼onoÅ›Ä‡ drzewa i pozwala na uchwycenie niuansÃ³w w danych.
Feature fraction: Parametr odpowiadajÄ…cy za losowe podprÃ³bkowanie cech (zakres okoÅ‚o 0.825â€“0.976) zapewnia element losowoÅ›ci, redukujÄ…c ryzyko przeuczenia.
Extra trees: W jednym z modeli wÅ‚Ä…czono dodatkowÄ… losowoÅ›Ä‡ (extra trees = True), co moÅ¼e zwiÄ™kszyÄ‡ rÃ³Å¼norodnoÅ›Ä‡ predykcji.
WspÃ³Å‚czynniki wagowe dla tych modeli (alpha_lgb) wynoszÄ… odpowiednio okoÅ‚o 2.26, 2.68 i 2.77, co oznacza, Å¼e ich predykcje majÄ… dominujÄ…cy wpÅ‚yw przy Å‚Ä…czeniu wynikÃ³w.

**Modele XGBoost**:
WÅ›rÃ³d dwÃ³ch trenowanych modeli XGBoost zastosowano m.in. nastÄ™pujÄ…ce ustawienia:

Learning rate: WartoÅ›Ä‡ okoÅ‚o 0.020 dla pierwszego modelu i znacznie mniejsza (okoÅ‚o 0.0012) dla drugiego, co sugeruje wiÄ™kszÄ… ostroÅ¼noÅ›Ä‡ w aktualizacji parametrÃ³w przy jednym z modeli.
Maksymalna gÅ‚Ä™bokoÅ›Ä‡ drzewa (max_depth): Wybrano gÅ‚Ä™bokoÅ›Ä‡ rÃ³wnÄ… 6 dla pierwszego modelu i 14 dla drugiego, co wpÅ‚ywa na zdolnoÅ›Ä‡ modelu do wychwytywania bardziej zÅ‚oÅ¼onych zaleÅ¼noÅ›ci.
Subsample oraz colsample_bytree: Parametry te (odpowiednio okoÅ‚o 0.823â€“0.864 oraz wartoÅ›Ä‡ rÃ³wnomiernie ustawiona na 1.0) sterujÄ… losowym wyborem prÃ³bek i cech przy budowie drzew, co poprawia generalizacjÄ™ modelu.
WspÃ³Å‚czynniki wagowe dla modeli XGBoost (alpha_xgb) to okoÅ‚o 1.55 oraz 0.35, wskazujÄ…ce, Å¼e predykcje pierwszego modelu XGBoost sÄ… waÅ¼niejsze przy ostatecznym Å‚Ä…czeniu wynikÃ³w.
''')
# Przyciski nawigacyjne
col1, col2, col3 = st.columns([3, 7, 2])
with col1:
    if st.button("WrÃ³Ä‡ do Wykresu"):
        switch_page("charts")

